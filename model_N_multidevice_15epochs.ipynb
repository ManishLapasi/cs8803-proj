{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "onJsDeQVm3pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision torchinfo torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW9kTqlg1UDo",
        "outputId": "712fb228-90de-47f1-bb49-96dbaf2e6c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pblMzrWSJNdL",
        "outputId": "c09bd369-bf9e-4b4e-879d-b47e532704c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXBFd_R51TmO"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch, torchinfo\n",
        "# import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms\n",
        "# import pandas as pd\n",
        "# import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data_path = './drive/MyDrive/cs8803_data/spectrograms/' #looking in subfolder train\n",
        "model_save_path = './drive/MyDrive/cs8803_data/models/'\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        " dev = \"cuda:0\"\n",
        "else:\n",
        " dev = \"cpu\"\n",
        "device = torch.device(dev)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "yHqCNuJOm7_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myImageFolder(ImageFolder):\n",
        "  @staticmethod\n",
        "  def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d)) and not d.startswith('.')]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx"
      ],
      "metadata": {
        "id": "z_yLMreu4iJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBZQ3VhY1TmS",
        "outputId": "b7e3dd3c-94a3-44c3-dd82-4ef5e2b4b243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset myImageFolder\n",
            "    Number of datapoints: 313\n",
            "    Root location: ./drive/MyDrive/cs8803_data/spectrograms/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(201, 1103), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "multi_dataset = myImageFolder(\n",
        "    root=data_path,\n",
        "    transform=transforms.Compose([transforms.Resize((201,1103)),\n",
        "                                  transforms.ToTensor()\n",
        "                                  ])\n",
        ")\n",
        "print(multi_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69-amY711TmT",
        "outputId": "7d1dd45e-8137-4165-dad3-4c255cf2cf10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class category and index of the images: {'blender': 0, 'garbage': 1, 'noise': 2}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class_map=multi_dataset.class_to_idx\n",
        "\n",
        "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XAquqUF1TmU",
        "outputId": "920818b1-4b89-4577-9235-3e0f1250d598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 250\n",
            "Testing size: 31\n",
            "Validation size: 32\n"
          ]
        }
      ],
      "source": [
        "#split data to test and train\n",
        "#use 80% to train\n",
        "train_size = int(0.8 * len(multi_dataset))\n",
        "test_size = int(0.1 * len(multi_dataset))\n",
        "val_size = len(multi_dataset) - train_size - test_size\n",
        "multi_train_dataset, multi_test_dataset, multi_val_dataset = torch.utils.data.random_split(multi_dataset, [train_size, test_size, val_size])\n",
        "\n",
        "print(\"Training size:\", len(multi_train_dataset))\n",
        "print(\"Testing size:\",len(multi_test_dataset))\n",
        "print(\"Validation size:\",len(multi_val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "w7uO7Bub1TmV",
        "outputId": "05953807-1987-4946-dab1-2ecdc634f7e6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-32e64dfaeb98>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# labels in training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmulti_train_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-32e64dfaeb98>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# labels in training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmulti_train_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# labels in training set\n",
        "train_classes = [label for _, label in multi_train_dataset]\n",
        "Counter(train_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z6rG0G71TmW"
      },
      "outputs": [],
      "source": [
        "test_classes = [label for _, label in multi_test_dataset]\n",
        "Counter(test_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PFrPuSa1TmW",
        "outputId": "0b24f8bb-0c2a-4d5d-aca3-32dd7d81582a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9529, 0.9922, 0.9922,  ..., 0.6980, 0.7490, 0.3412])\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    multi_train_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    multi_test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    multi_val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True\n",
        ")\n",
        "td = train_dataloader.dataset[0][0][0][0]\n",
        "print(td)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "8AEeIpBDnAlt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8fg_Tbn1TmX",
        "outputId": "d44f69f1-da93-4b27-a3f4-643f1dad92d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using AMD Radeon RX 6800M\u0000 device\n"
          ]
        }
      ],
      "source": [
        "import torch_directml\n",
        "tensor_dev = torch_directml.device(0)\n",
        "print('Using {} device'.format(torch_directml.device_name(tensor_dev.index)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_dev = device"
      ],
      "metadata": {
        "id": "EoPIEXGt52C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj_7B8JE1TmX"
      },
      "outputs": [],
      "source": [
        "class CNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(841728, 50)\n",
        "        self.fc2 = nn.Linear(50, 3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return F.sigmoid(x)\n",
        "\n",
        "model = CNNet().to(tensor_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb9qvQBg1TmY",
        "outputId": "5a21da58-87ee-4b83-e455-3f4d7829f046"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "CNNet                                    --\n",
              "├─Conv2d: 1-1                            896\n",
              "├─Conv2d: 1-2                            18,496\n",
              "├─Dropout2d: 1-3                         --\n",
              "├─Flatten: 1-4                           --\n",
              "├─Linear: 1-5                            42,086,450\n",
              "├─Linear: 1-6                            153\n",
              "=================================================================\n",
              "Total params: 42,105,995\n",
              "Trainable params: 42,105,995\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W9Njoz21TmZ"
      },
      "outputs": [],
      "source": [
        "# cost function used to determine best parameters\n",
        "cost = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# used to create optimal parameters\n",
        "learning_rate = 1e-6\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCQjkCjm1TmZ"
      },
      "outputs": [],
      "source": [
        "model.to(tensor_dev)\n",
        "\n",
        "accs = []\n",
        "stop_model_train_threshold = 5\n",
        "\n",
        "# Create the training function\n",
        "\n",
        "def train(dataloader, model, loss, optimizer):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, Y) in enumerate(dataloader):\n",
        "\n",
        "        X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = cost(pred, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
        "\n",
        "\n",
        "# Create the validation/test function\n",
        "\n",
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, Y) in enumerate(dataloader):\n",
        "            X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
        "            pred = model(X)\n",
        "\n",
        "            test_loss += cost(pred, Y).item()\n",
        "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "\n",
        "    accs.append(100*correct)\n",
        "\n",
        "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_j5cfzi1TmZ",
        "outputId": "55c4f8f8-d41c-47a3-b6ce-61f00577d3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.086392  [    0/  250]\n",
            "loss: 1.098612  [  100/  250]\n",
            "loss: 1.098612  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 32.3%, avg loss: 1.095087\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.098612  [    0/  250]\n",
            "loss: 1.098612  [  100/  250]\n",
            "loss: 1.119276  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 32.3%, avg loss: 1.087462\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.100138  [    0/  250]\n",
            "loss: 0.914695  [  100/  250]\n",
            "loss: 1.167600  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 77.4%, avg loss: 1.061428\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.070401  [    0/  250]\n",
            "loss: 0.998737  [  100/  250]\n",
            "loss: 0.948608  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 71.0%, avg loss: 1.044311\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.273614  [    0/  250]\n",
            "loss: 1.111812  [  100/  250]\n",
            "loss: 1.042237  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 77.4%, avg loss: 1.026241\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.023414  [    0/  250]\n",
            "loss: 1.164861  [  100/  250]\n",
            "loss: 1.049072  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 1.011569\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.974210  [    0/  250]\n",
            "loss: 1.100077  [  100/  250]\n",
            "loss: 1.000500  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.986698\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.087137  [    0/  250]\n",
            "loss: 1.095863  [  100/  250]\n",
            "loss: 1.119321  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.969396\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.000914  [    0/  250]\n",
            "loss: 1.126685  [  100/  250]\n",
            "loss: 0.919927  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.952815\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.135169  [    0/  250]\n",
            "loss: 1.133958  [  100/  250]\n",
            "loss: 1.104701  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.937072\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.917950  [    0/  250]\n",
            "loss: 1.013259  [  100/  250]\n",
            "loss: 0.966710  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.923719\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.032402  [    0/  250]\n",
            "loss: 0.930315  [  100/  250]\n",
            "loss: 0.914003  [  200/  250]\n",
            "\n",
            "Test Error:\n",
            "acc: 100.0%, avg loss: 0.911204\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 25\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f'Epoch {t+1}\\n-------------------------------')\n",
        "    train(train_dataloader, model, cost, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "    if len(accs)>1 and accs[-1]-accs[-2] <= stop_model_train_threshold and t > 10: break\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBFM3iTc1Tma",
        "outputId": "1eef75fb-2486-4387-e5d8-2df3368e5973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Actual:\n",
            "value=2, class_name= noise\n",
            "\n",
            "Predicted:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Actual:\n",
            "value=1, class_name= garbage\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Predicted:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Actual:\n",
            "value=0, class_name= blender\n",
            "\n",
            "Correct count = 32\n",
            "Accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "model.to(tensor_dev).eval()\n",
        "#model.eval()\n",
        "#class_map = ['blender', 'noise']\n",
        "class_map = ['blender', 'garbage', 'noise']\n",
        "\n",
        "cf_matrix = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
        "\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for batch, (X, Y) in enumerate(val_dataloader):\n",
        "        X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
        "        pred = model(X)\n",
        "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
        "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
        "        if pred[0].argmax(0)==Y[0]:\n",
        "          correct += 1\n",
        "        else:\n",
        "          print(\"incorrect!\")\n",
        "        cf_matrix[Y[0]][pred[0].argmax(0)] += 1\n",
        "    print('Correct count = {}'.format(correct))\n",
        "    print('Accuracy = {}'.format(correct/len(val_dataloader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E2eYNGXVO0q",
        "outputId": "5247fd28-f24c-43f6-ddad-f7090950639c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  0,  0],\n",
              "       [ 0, 10,  0],\n",
              "       [ 0,  0, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f\"{model_save_path}/model.pth\")"
      ],
      "metadata": {
        "id": "qcT5O27AtD2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_9j1l1P1Tma"
      },
      "outputs": [],
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "y = model(X).to(tensor_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cbc6okhv1Tma",
        "outputId": "b945fd61-a188-4d24-f265-16917de260de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vertical_layout_graph.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "dot = make_dot(y, params=dict(model.named_parameters()))\n",
        "dot.graph_attr['rankdir'] = 'TB'\n",
        "dot.render(\"vertical_layout_graph\", format=\"png\", cleanup=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ku6GgO1q7PtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "yHqCNuJOm7_E"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}