{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "# import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "data_path = './data/spectrograms' #looking in subfolder train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 223\n",
      "    Root location: ./data/spectrograms\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(201, 1103), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "multi_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((201,1103)),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(multi_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'blender': 0, 'garbage': 1, 'noise': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=multi_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 178\n",
      "Testing size: 45\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(multi_dataset))\n",
    "test_size = len(multi_dataset) - train_size\n",
    "multi_train_dataset, multi_test_dataset = torch.utils.data.random_split(multi_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(multi_train_dataset))\n",
    "print(\"Testing size:\",len(multi_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 91, 2: 80, 1: 7})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in multi_train_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 23, 0: 19, 1: 3})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = [label for _, label in multi_test_dataset]\n",
    "Counter(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7412, 0.7098, 0.7098,  ..., 0.7922, 0.7490, 0.8039])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    multi_train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    multi_test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")\n",
    "td = train_dataloader.dataset[0][0][0][0]\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AMD Radeon RX 6800M\u0000 device\n"
     ]
    }
   ],
   "source": [
    "import torch_directml\n",
    "tensor_dev = torch_directml.device(0)\n",
    "print('Using {} device'.format(torch_directml.device_name(tensor_dev.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(841728, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.sigmoid(x)  \n",
    "\n",
    "model = CNNet().to(tensor_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CNNet                                    --\n",
       "├─Conv2d: 1-1                            896\n",
       "├─Conv2d: 1-2                            18,496\n",
       "├─Dropout2d: 1-3                         --\n",
       "├─Flatten: 1-4                           --\n",
       "├─Linear: 1-5                            42,086,450\n",
       "├─Linear: 1-6                            153\n",
       "=================================================================\n",
       "Total params: 42,105,995\n",
       "Trainable params: 42,105,995\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(tensor_dev)\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        \n",
    "        X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.111292  [    0/  178]\n",
      "loss: 0.917433  [  100/  178]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.3%, avg loss: 0.968000\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.947388  [    0/  178]\n",
      "loss: 0.797117  [  100/  178]\n",
      "\n",
      "Test Error:\n",
      "acc: 100.0%, avg loss: 0.921845\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Actual:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Actual:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Actual:\n",
      "value=1, class_name= garbage\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Actual:\n",
      "value=2, class_name= noise\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Predicted:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= blender\n",
      "\n",
      "Correct count = 45\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "model.to(tensor_dev).eval()\n",
    "class_map = ['blender', 'garbage', 'noise']\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        X, Y = X.to(tensor_dev), Y.to(tensor_dev)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
    "        correct += 1 if pred[0].argmax(0)==Y[0] else 0\n",
    "    print('Correct count = {}'.format(correct))\n",
    "    print('Accuracy = {}'.format(correct/len(test_dataloader)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
